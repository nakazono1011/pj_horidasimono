{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 22 04:59:12 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   44C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6138784958283831166, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11280557671\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4354696728565191315\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "import re, MeCab\n",
    "from glob import glob\n",
    "import mojimoji\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.core import Activation, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "#環境変数,\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"../auth/My First Project.json\"\n",
    "bucket_name = \"pj_horidasimono\"\n",
    "prefix=\"dataset/train/ElectricalAppliance\"\n",
    "#最大表示行数の指定（ここでは50行を指定）\n",
    "pd.set_option('display.max_rows', 200)\n",
    "#最大表示列数の指定（ここでは50列を指定）\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- ----------\n",
      "absl-py                            0.6.1\n",
      "alabaster                          0.7.10\n",
      "anaconda-client                    1.6.14\n",
      "anaconda-project                   0.8.2\n",
      "asn1crypto                         0.24.0\n",
      "astor                              0.7.1\n",
      "astroid                            1.6.3\n",
      "astropy                            3.0.2\n",
      "attrs                              18.1.0\n",
      "Automat                            0.3.0\n",
      "autovizwidget                      0.12.6\n",
      "Babel                              2.5.3\n",
      "backcall                           0.1.0\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "beautifulsoup4                     4.6.0\n",
      "bitarray                           0.8.1\n",
      "bkcharts                           0.2\n",
      "blaze                              0.11.3\n",
      "bleach                             2.1.3\n",
      "bokeh                              0.12.13\n",
      "boto                               2.48.0\n",
      "boto3                              1.9.50\n",
      "botocore                           1.12.50\n",
      "Bottleneck                         1.2.1\n",
      "cached-property                    1.5.1\n",
      "cachetools                         4.1.1\n",
      "certifi                            2018.10.15\n",
      "cffi                               1.11.5\n",
      "characteristic                     14.3.0\n",
      "chardet                            3.0.4\n",
      "click                              6.7\n",
      "cloudpickle                        0.5.3\n",
      "clyent                             1.2.2\n",
      "colorama                           0.3.9\n",
      "contextlib2                        0.5.5\n",
      "cryptography                       2.2.2\n",
      "cycler                             0.10.0\n",
      "Cython                             0.28.4\n",
      "cytoolz                            0.9.0.1\n",
      "dask                               0.17.5\n",
      "datashape                          0.5.4\n",
      "decorator                          4.3.0\n",
      "distributed                        1.21.8\n",
      "docker                             3.5.1\n",
      "docker-compose                     1.23.1\n",
      "docker-pycreds                     0.3.0\n",
      "dockerpty                          0.4.1\n",
      "docopt                             0.6.2\n",
      "docutils                           0.14\n",
      "entrypoints                        0.2.3\n",
      "environment-kernels                1.1.1\n",
      "et-xmlfile                         1.0.1\n",
      "fastcache                          1.0.2\n",
      "filelock                           3.0.4\n",
      "Flask                              1.0.2\n",
      "Flask-Cors                         3.0.4\n",
      "gast                               0.2.0\n",
      "gevent                             1.3.0\n",
      "glob2                              0.6\n",
      "gmpy2                              2.0.8\n",
      "google-api-core                    1.23.0\n",
      "google-auth                        1.22.1\n",
      "google-cloud                       0.34.0\n",
      "google-cloud-core                  1.4.3\n",
      "google-cloud-storage               1.32.0\n",
      "google-crc32c                      1.0.0\n",
      "google-resumable-media             1.1.0\n",
      "googleapis-common-protos           1.52.0\n",
      "greenlet                           0.4.13\n",
      "grpcio                             1.10.1\n",
      "h5py                               2.8.0\n",
      "hdijupyterutils                    0.12.6\n",
      "heapdict                           1.0.0\n",
      "horovod                            0.14.1\n",
      "html5lib                           1.0.1\n",
      "idna                               2.6\n",
      "imageio                            2.3.0\n",
      "imagesize                          1.0.0\n",
      "ipykernel                          4.8.2\n",
      "ipyparallel                        6.2.2\n",
      "ipython                            6.4.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.4.0\n",
      "isort                              4.3.4\n",
      "itsdangerous                       0.24\n",
      "jdcal                              1.4\n",
      "jedi                               0.12.0\n",
      "Jinja2                             2.10\n",
      "jmespath                           0.9.3\n",
      "jsonschema                         2.6.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     5.2.3\n",
      "jupyter-console                    5.2.0\n",
      "jupyter-core                       4.4.0\n",
      "jupyterlab                         0.32.1\n",
      "jupyterlab-launcher                0.10.5\n",
      "Keras                              2.2.4\n",
      "Keras-Applications                 1.0.6\n",
      "Keras-Preprocessing                1.1.2\n",
      "kiwisolver                         1.0.1\n",
      "lazy-object-proxy                  1.3.1\n",
      "llvmlite                           0.23.1\n",
      "locket                             0.2.0\n",
      "lxml                               4.2.1\n",
      "Markdown                           3.0.1\n",
      "MarkupSafe                         1.0\n",
      "matplotlib                         2.2.2\n",
      "mccabe                             0.6.1\n",
      "mecab-python3                      1.0.2\n",
      "mistune                            0.8.3\n",
      "mkl-fft                            1.0.0\n",
      "mkl-random                         1.0.1\n",
      "mock                               2.0.0\n",
      "mojimoji                           0.0.11\n",
      "more-itertools                     4.1.0\n",
      "mpmath                             1.0.0\n",
      "msgpack                            0.5.6\n",
      "msgpack-python                     0.5.6\n",
      "multipledispatch                   0.5.0\n",
      "nb-conda                           2.2.1\n",
      "nb-conda-kernels                   2.2.0\n",
      "nbconvert                          5.3.1\n",
      "nbformat                           4.4.0\n",
      "networkx                           2.1\n",
      "nltk                               3.3\n",
      "nose                               1.3.7\n",
      "notebook                           5.5.0\n",
      "numba                              0.38.0\n",
      "numexpr                            2.6.5\n",
      "numpy                              1.14.5\n",
      "numpydoc                           0.8.0\n",
      "odo                                0.5.1\n",
      "olefile                            0.45.1\n",
      "openpyxl                           2.5.3\n",
      "packaging                          17.1\n",
      "pandas                             0.22.0\n",
      "pandocfilters                      1.4.2\n",
      "parso                              0.2.0\n",
      "partd                              0.3.8\n",
      "path.py                            11.0.1\n",
      "pathlib2                           2.3.2\n",
      "patsy                              0.5.0\n",
      "pbr                                5.1.1\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.5.0\n",
      "pickleshare                        0.7.4\n",
      "Pillow                             5.2.0\n",
      "pip                                20.2.4\n",
      "pkginfo                            1.4.2\n",
      "plotly                             2.7.0\n",
      "pluggy                             0.6.0\n",
      "ply                                3.11\n",
      "prompt-toolkit                     1.0.15\n",
      "protobuf                           3.13.0\n",
      "protobuf3-to-dict                  0.1.5\n",
      "psutil                             5.4.5\n",
      "psycopg2                           2.7.5\n",
      "ptyprocess                         0.5.2\n",
      "py                                 1.5.3\n",
      "py4j                               0.10.4\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.4.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.18\n",
      "pycrypto                           2.6.1\n",
      "pycurl                             7.43.0.1\n",
      "pyflakes                           1.6.0\n",
      "pygal                              2.4.0\n",
      "Pygments                           2.2.0\n",
      "pykerberos                         1.2.1\n",
      "pylint                             1.8.4\n",
      "pyodbc                             4.0.23\n",
      "pyOpenSSL                          18.0.0\n",
      "pyparsing                          2.2.0\n",
      "PySocks                            1.6.8\n",
      "pyspark                            2.2.1\n",
      "pytest                             3.5.1\n",
      "pytest-arraydiff                   0.2\n",
      "pytest-astropy                     0.3.0\n",
      "pytest-doctestplus                 0.1.3\n",
      "pytest-openfiles                   0.3.0\n",
      "pytest-remotedata                  0.2.1\n",
      "python-dateutil                    2.7.3\n",
      "pytz                               2018.4\n",
      "PyWavelets                         0.5.2\n",
      "PyYAML                             3.12\n",
      "pyzmq                              17.0.0\n",
      "QtAwesome                          0.4.4\n",
      "qtconsole                          4.3.1\n",
      "QtPy                               1.4.1\n",
      "requests                           2.20.0\n",
      "requests-kerberos                  0.12.0\n",
      "rope                               0.10.7\n",
      "rsa                                4.6\n",
      "ruamel-yaml                        0.15.35\n",
      "s3fs                               0.1.5\n",
      "s3transfer                         0.1.13\n",
      "sagemaker                          1.15.2\n",
      "sagemaker-pyspark                  1.2.1\n",
      "scikit-image                       0.13.1\n",
      "scikit-learn                       0.19.1\n",
      "scipy                              1.1.0\n",
      "seaborn                            0.8.1\n",
      "Send2Trash                         1.5.0\n",
      "setuptools                         50.3.2\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.4.0.3\n",
      "six                                1.15.0\n",
      "sklearn                            0.0\n",
      "snowballstemmer                    1.2.1\n",
      "sortedcollections                  0.6.1\n",
      "sortedcontainers                   1.5.10\n",
      "sparkmagic                         0.12.5\n",
      "Sphinx                             1.7.4\n",
      "sphinxcontrib-websupport           1.0.1\n",
      "spyder                             3.2.8\n",
      "SQLAlchemy                         1.2.11\n",
      "statsmodels                        0.9.0\n",
      "sympy                              1.1.1\n",
      "tables                             3.4.3\n",
      "tblib                              1.3.2\n",
      "tensorboard                        1.12.0\n",
      "tensorflow                         1.12.0\n",
      "tensorflow-gpu                     1.12.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.8.1\n",
      "testpath                           0.3.1\n",
      "texttable                          0.9.1\n",
      "toolz                              0.9.0\n",
      "tornado                            5.0.2\n",
      "traitlets                          4.3.2\n",
      "typing                             3.6.4\n",
      "unicodecsv                         0.14.1\n",
      "urllib3                            1.22\n",
      "wcwidth                            0.1.7\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   0.54.0\n",
      "Werkzeug                           0.14.1\n",
      "wheel                              0.31.1\n",
      "widgetsnbextension                 3.4.2\n",
      "wrapt                              1.12.1\n",
      "xlrd                               1.1.0\n",
      "XlsxWriter                         1.0.4\n",
      "xlwt                               1.3.0\n",
      "zict                               0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def road_data_from_gcs(bucket_name, prefix):\n",
    "    client = storage.Client()\n",
    "    blobs = client.list_blobs(bucket_name, prefix=prefix)\n",
    "    df = pd.DataFrame()\n",
    "    for blob in blobs:\n",
    "        bucket = client.get_bucket(bucket_name)\n",
    "        r = storage.Blob(blob.name, bucket)\n",
    "        content = r.download_as_string()\n",
    "        df = df.append(pd.read_json(content))\n",
    "        print(f\"read file {blob.name}...\")\n",
    "\n",
    "    df = df.drop_duplicates(subset=\"url\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "def make_wakati(sentence):\n",
    "    # MeCabで分かち書き\n",
    "    sentence = tagger.parse(sentence)\n",
    "    sentence = mojimoji.zen_to_han(sentence)\n",
    "    # 半角全角英数字除去\n",
    "    #sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
    "    # 記号もろもろ除去\n",
    "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—♬◉ᴗ͈ˬ●★☆⭐️⭕⚡⚠o①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮♡⭐︎〇◎◆♦▼◇△□(：〜～＋=)／*&^%$#@!~`)♪ᴖ◡ᴖ{}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕＼〈〉？、､。｡・,\\./『』【】｢｣「」→←○《》≪≫\\n\\u3000⭕]+', \"\", sentence)\n",
    "    # 絵文字除去\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    sentence = emoji_pattern.sub(r'', sentence)\n",
    "    # スペースで区切って形態素の配列へ\n",
    "    #wakati = sentence.split(\" \")\n",
    "    # 空の要素は削除\n",
    "    #wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return sentence\n",
    "\n",
    "def title_torkenize(sentence):\n",
    "    sentence = mojimoji.zen_to_han(sentence)\n",
    "    sentence = re.sub(\"[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒♬◉ᴗ͈ˬ—●★☆⭐️⭕⚡⚠o①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮♡⭐︎〇◎◆♦▼◇△□(：〜～＋=)／*&^%$#@!~`)♪ᴖ◡ᴖ{}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕＼〈〉？、､。｡・,\\./『』【】｢｣「」→←○《》≪≫\\n\\u3000]\", \" \", sentence)\n",
    "    sentence = re.sub(\"[あ-ん]\", \" \", sentence)\n",
    "    sentence = re.sub(\"( |　)+\", \" \", sentence)\n",
    "    sentence = sentence.lower()\n",
    "    #〇〇様専用を除く\n",
    "    sentence = re.sub(\"[^ ]*専用\", \"\", sentence)\n",
    "    sentence = re.sub(\"[^ ]*様\", \"\", sentence)\n",
    "    #1文字のアルファベットを除く\n",
    "    sentence = re.sub(\" [a-z]{1}[^(a-z)]\", \" \", sentence)\n",
    "    # 絵文字除去\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    sentence = emoji_pattern.sub(r'', sentence)\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def preprocess(df):\n",
    "    df[\"price\"] = df[\"price\"].str.replace(r\"\\D\", \"\").astype(np.float)\n",
    "    \n",
    "    #列ズレを修正\n",
    "    pattern = re.compile(r\"^(?!.*(傷や汚れあり|全体的に状態が悪い|やや傷や汚れあり|未使用に近い|目立った傷や汚れなし|新品、未使用)).+$\")\n",
    "    invalid = df[\"status\"].str.match(pattern)\n",
    "\n",
    "    df.loc[invalid, \"description\"] = df.loc[invalid, \"description\"] + \"\\n\" + df.loc[invalid, \"status\"]\n",
    "    df.loc[invalid, \"status\"]      = df.loc[invalid, \"shipping\"]\n",
    "    df.loc[invalid, \"shipping\"]    = df.loc[invalid, \"method\"]\n",
    "    df.loc[invalid, \"method\"]      = df.loc[invalid, \"region\"]\n",
    "    df.loc[invalid, \"period\"]      = \"未定\"\n",
    "    \n",
    "    df[\"title\"] = df[\"title\"] + \" \" + df[\"sub_category_1\"] + \" \" + df[\"sub_category_2\"] + \" \" + df[\"brand\"]\n",
    "    #df[\"text\"]  = df[\"title\"] + \" \" + df[\"description\"]\n",
    "\n",
    "    df = df.drop(columns=[\"sub_category_1\", \"sub_category_2\", \"brand\"])\n",
    "    \n",
    "    status_dict = {'新品、未使用': \"best\",\n",
    "                   '未使用に近い': \"Very Good\",\n",
    "                   '目立った傷や汚れなし': \"good\",\n",
    "                   '傷や汚れあり': \"Poor\",\n",
    "                   'やや傷や汚れあり': \"very poor\",\n",
    "                   '全体的に状態が悪い': \"worst\"\n",
    "                  }\n",
    "    \n",
    "    #配送負担をラベルエンコーディング\n",
    "    shipping_dict = {'送料込み(出品者負担)': 0, '着払い(購入者負担)': 1}\n",
    "\n",
    "    df[\"status\"] = df[\"status\"].map(status_dict)\n",
    "    df[\"shipping\"] = df[\"shipping\"].map(shipping_dict)\n",
    "    \n",
    "    #トークナイズ\n",
    "    df[\"title\"] = df[\"title\"].apply(title_torkenize)\n",
    "    df[\"description\"] = df[\"description\"].apply(make_wakati)\n",
    "    \n",
    "    #不要列削除\n",
    "    df = df.drop(columns=[\"url\", \"seller\", \"rating\", \"method\", \"region\", \"period\", \"recent_comment\", \"timestamp\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/pj_horidasimono/code\n"
     ]
    }
   ],
   "source": [
    "cd ../code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_ridge import ModelRidge\n",
    "from model_nn import ModelNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ = road_data_from_gcs(bucket_name, prefix)\n",
    "df_ = pd.read_pickle(\"../dataset/df1022.pickle\")\n",
    "#df_.to_pickle(\"../dataset/df1022.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "                            'input_dropout': 0.0,\n",
    "                            'hidden_layers': 3,\n",
    "                            'hidden_units': 96,\n",
    "                            'hidden_activation': 'relu',\n",
    "                            'hidden_dropout': 0.2,\n",
    "                            'batch_norm': 'before_act',\n",
    "                            'optimizer': {'type': 'adam', 'lr': 0.001},\n",
    "                            'batch_size': 64,\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess] done in 96 s\n",
      "Train on 129555 samples, validate on 32389 samples\n",
      "Epoch 1/200\n",
      " 91200/129555 [====================>.........] - ETA: 5:16 - loss: 0.6244"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "def on_field(f: str, *vec):\n",
    "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)\n",
    "\n",
    "def to_records(df: pd.DataFrame):\n",
    "    return df.to_dict(orient='records')\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "vectorizer = make_union(\n",
    "            on_field(\"title\", Tfidf(max_features=100000, token_pattern=\"\\w+\")),\n",
    "            on_field(\"description\", Tfidf(max_features=500000, token_pattern=\"\\w+\", ngram_range=(1, 2))),\n",
    "            on_field(['shipping', 'status'],\n",
    "                 FunctionTransformer(to_records, validate=False), DictVectorizer()))\n",
    "\n",
    "with timer(\"preprocess\"):\n",
    "    df = preprocess(df_.copy())\n",
    "    X = df.drop(columns=\"price\")\n",
    "    y = df[\"price\"]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    X_train = vectorizer.fit_transform(X_train).astype(np.float32)\n",
    "    X_valid = vectorizer.transform(X_valid).astype(np.float32)\n",
    "    Xb_train, Xb_valid = [x.astype(np.bool).astype(np.float32) for x in [X_train, X_valid]]\n",
    "    \n",
    "    xs = [[Xb_train, Xb_valid], [X_train, X_valid]] * 2\n",
    "\n",
    "with timer(\"fit and predict\"):\n",
    "    preds = []\n",
    "    for X_tr, X_val in xs:\n",
    "        model = ModelNN(base_params)\n",
    "        model.fit(X_tr, y_train, X_val, y_valid)\n",
    "        pred = np.expm1(model.predict(X_valid))\n",
    "        preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3921.00073941, 10722.54178525,  3015.72987121,  6307.71814086,\n",
       "         5837.41511324,  4124.91457758,  3318.73857373, 10388.81354219,\n",
       "         9276.01570235,  4403.37482128],\n",
       "       [ 5033.77274055,  8672.69665585,  3291.10274213,  7334.94270278,\n",
       "         6168.25854082,  4247.94608789,  4581.66158334,  7324.05772586,\n",
       "         9005.50807571,  4207.85018395],\n",
       "       [ 3925.23032733, 10715.00034578,  3016.61798409,  6306.63922998,\n",
       "         5834.43025584,  4127.43910608,  3317.39577228, 10391.9404367 ,\n",
       "         9283.17776722,  4396.11391128],\n",
       "       [ 5033.77423575,  8672.70156269,  3291.10094743,  7334.93930372,\n",
       "         6168.25372722,  4247.94592174,  4581.66296965,  7324.04847944,\n",
       "         9005.50674726,  4207.85583122]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds)[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.584205749403832\n",
      "49.22214812364832\n",
      "0.4560177175726792\n",
      "36.77099050851783\n",
      "0.5842012810989269\n",
      "49.22075733874581\n",
      "0.4560177162274387\n",
      "36.77099165179877\n",
      "0.48854135389353986\n"
     ]
    }
   ],
   "source": [
    "for pred in np.array(preds):\n",
    "    print(np.sqrt(mean_squared_log_error(y_valid, pred)))\n",
    "    print(np.mean(np.abs((y_valid - pred) / y_valid)) * 100)\n",
    "\n",
    "print(np.sqrt(mean_squared_log_error(y_valid, np.mean(np.array(preds), axis=0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "va_pred = np.expm1(model.predict(X_valid))\n",
    "score = np.sqrt(mean_squared_log_error(y_valid, va_pred))\n",
    "mape = np.mean(np.abs((y_valid - va_pred) / y_valid)) * 100\n",
    "print(\"mape: {:.3f}%\".format(mape))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "3 4\n"
     ]
    }
   ],
   "source": [
    "a = [[1, 2], [3, 4]]\n",
    "for i, j in a:\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Doc2Vec(documents= trainings, dm = 1, size=300, window=8, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('doc2vec.model')\n",
    "#model = models.Doc2Vec.load('doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.infer_vector([\"宜しく\", \"どうぞ\", \"付属\", \"品\", \"は\", \"画像\", \"が\", \"全て\", \"です\",  \"問題\", \"なく\", \"動作\", \"確認\", \"済み\", \"です\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "vectorizer = Vectorizer().tfidf_vectorizer(title_feat=100000, description_feat=500000)\n",
    "\n",
    "with timer(\"preprocess\"):\n",
    "    df = preprocess(df_.copy())\n",
    "    X = df.drop(columns=\"price\")\n",
    "    y = df[\"price\"]\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    X_train = vectorizer.fit_transform(X_train).astype(np.float32)\n",
    "    X_valid = vectorizer.transform(X_valid).astype(np.float32)\n",
    "    Xb_train, Xb_valid = [x.astype(np.bool).astype(np.float32) for x in [X_train, X_valid]]\n",
    "    \n",
    "    xs = [[Xb_train, Xb_valid], [X_train, X_valid]] * 2\n",
    "\n",
    "with timer(\"fit and predict\"):\n",
    "    preds = []\n",
    "    for X_train, X_valid in xs:\n",
    "        model = ModelRidge()\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = np.expm1(model.predict(X_valid))\n",
    "        preds.append(pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
